#### BEGIN LAYER 1 CONFIGURATION

# we define the node_bridge_config vars here and not in the host-specific config file,
# because it depends on the rollout scenario (all-in-one vs. multi-node) which interfaces
# are being bridged and whether or not additional IPs need to be configured (e.g. for admin IP to the ndoes)
[sddc]
FE-SDDC-RH10r ansible_host=10.116.127.149 node_bridge_config="{ 'services':{'nic':'srv-bond','host_prefix':'10.116.127.149/24','default_gw':'10.116.127.254', 'additional':'DEFROUTE=\"yes\"\nDNS1=10.116.57.11\nDOMAIN=rh-sddc.test-bosch.com'}, 'admin':{'nic':'james-bond','host_prefix':'192.168.23.149/24'}, 'internal_api':{'nic':'james-bond'}, 'tenant':{'nic':'james-bond'}, 'storage':{'nic':'james-bond'}, 'storage_mgmt':{'nic':'james-bond'}, 'provisioning':{'nic':'prov-bond'}, 'bgp1':{'nic':'james-bond'}, 'bgp2':{'nic':'james-bond'}, 'ospf1':{'nic':'james-bond'}, 'ospf2':{'nic':'james-bond'}, 'baremetal':{'nic':'james-bond'}, 'nuage_vsr':{'nic':'james-bond'} }"
FE-SDDC-RH11r ansible_host=10.116.127.150 node_bridge_config="{ 'services':{'nic':'srv-bond','host_prefix':'10.116.127.150/24','default_gw':'10.116.127.254', 'additional':'DEFROUTE=\"yes\"\nDNS1=10.116.57.11\nDOMAIN=rh-sddc.test-bosch.com'}, 'admin':{'nic':'james-bond','host_prefix':'192.168.23.150/24'}, 'internal_api':{'nic':'james-bond'}, 'tenant':{'nic':'james-bond'}, 'storage':{'nic':'james-bond'}, 'storage_mgmt':{'nic':'james-bond'}, 'provisioning':{'nic':'prov-bond'}, 'bgp1':{'nic':'james-bond'}, 'bgp2':{'nic':'james-bond'}, 'ospf1':{'nic':'james-bond'}, 'ospf2':{'nic':'james-bond'}, 'baremetal':{'nic':'james-bond'}, 'nuage_vsr':{'nic':'james-bond'} }"
FE-SDDC-RH12r ansible_host=10.116.127.151 node_bridge_config="{ 'services':{'nic':'srv-bond','host_prefix':'10.116.127.151/24','default_gw':'10.116.127.254', 'additional':'DEFROUTE=\"yes\"\nDNS1=10.116.57.11\nDOMAIN=rh-sddc.test-bosch.com'}, 'admin':{'nic':'james-bond','host_prefix':'192.168.23.151/24'}, 'internal_api':{'nic':'james-bond'}, 'tenant':{'nic':'james-bond'}, 'storage':{'nic':'james-bond'}, 'storage_mgmt':{'nic':'james-bond'}, 'provisioning':{'nic':'prov-bond'}, 'bgp1':{'nic':'james-bond'}, 'bgp2':{'nic':'james-bond'}, 'ospf1':{'nic':'james-bond'}, 'ospf2':{'nic':'james-bond'}, 'baremetal':{'nic':'james-bond'}, 'nuage_vsr':{'nic':'james-bond'} }"

[sddc:vars]
ansible_ssh_common_args="-i ./binary/{{ hailstorm_ssh_priv_key_file }} -o StrictHostKeyChecking=no"
nic_attachments="[ {{ infrastructure_network_services }} ]"

# the layer1 group should only contain a single server called layer1
[layer1-group]
layer1          ansible_host=192.168.23.1 node_bridge_config='{{ hostvars[layer1_ansible_host].node_bridge_config }}'

#### END LAYER 1 CONFIGURATION



#### BEGIN BASE SERVICES

[satellite-group]
satellite       l1host="FE-SDDC-RH10r" ansible_host=10.116.127.152

# the IPA server
[ipa-group]
ipa             l1host="FE-SDDC-RH10r" ansible_host=10.116.127.153 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}"

[install-host-group]
install-host    l1host="FE-SDDC-RH10r" ansible_host=10.116.127.154 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}"

#### END BASE SERVICES



#### BEGIN ADDITIONAL L2 VMS

# Elasticsearch, FluentD, Kibana
[efk-group]
efk             l1host="FE-SDDC-RH12r" ansible_host=10.116.127.174 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}"

# the Infrastructure server (DNS, SMTP/IMAP)
[infrastructure-group]
infrastructure  ansible_host=10.116.127.155 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" additional_dns="imap,smtp,ntp,vsd" roles=["dnat","smtp","haproxy","ntp","syslog"]
#syslog		      ansible_host=10.116.127.9 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" roles=["syslog"]

# which system will host virt-who -> this should not be satellite since virt-who reports to subscription-manager which reports to RHN (which doesn't know the Default Organization) on satellite
[virt-who]
infrastructure


#### END ADDITIONAL L2 VMS


#### BEGIN SYSTEM CONTEXT EMULATION

# bosch-vpn only for COE MUC deployment
[bosch-vpn-group]
bosch-vpn       l1host="layer1" ansible_host=10.116.127.19 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}"

# proxy only for COE MUC deployment
[proxy-group]
proxy           ansible_host=10.116.127.8 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}"

[windows-group]
## same IP as storage-console or syslog
si8ads13 ansible_host=10.116.127.9 ad_domain_name="rh-sddc.test-bosch.com" ad_netbios_name="ad-{{ inventory_hostname_short }}"
#si8ads14 ansible_host=10.116.127.6 ad_domain_name="de-rh.rh-sddc.test-bosch.com" ad_netbios_name="ad-{{ inventory_hostname_short }}"
#si8ads15 ansible_host=10.116.127.5 ad_domain_name="emea-rh.rh-sddc.test-bosch.com" ad_netbios_name="ad-{{ inventory_hostname_short }}"

[windows-group:vars]
ansible_user=Administrator
ansible_password="{{ root_passwordÂ }}"
ansible_port=5986
ansible_connection=winrm
# The following is necessary for Python 2.7.9+ (or any older Python that has backported SSLContext, eg, Python 2.7.5 on RHEL7) when using default WinRM self-signed certificates:
ansible_winrm_server_cert_validation=ignore

[primary-ad-group]
si8ads13

#### END SYSTEM CONTEXT EMULATION



#### BEGIN RED HAT VIRTUALIZATION

# the single node that is RHEV-Manager
[rhvm-group]
#rhvm           ansible_host=10.116.127.XXX activation_key="AK-CV-RHEV-MANAGER-{{ stage }}" additional_dns="rhv"

# the nodes that are RHEV-Hypervisor
[rhvh-group]
#rhvh1          ansible_host=10.116.127.XXX activation_key="AK-CV-RHEV-HYPERVISOR-{{ stage }}"
#rhvh2          ansible_host=10.116.127.XXX activation_key="AK-CV-RHEV-HYPERVISOR-{{ stage }}"
#rhvh3          ansible_host=10.116.127.XXX activation_key="AK-CV-RHEV-HYPERVISOR-{{ stage }}"

# the list of groups that make up RHEV
[rhv-group:children]
rhvm-group
rhvh-group

# all RHEV nodes and the layer1 host to ensure there's a common view on the storage domain
[layer1-rhv-group:children]
rhv-group
layer1-group

#### END RED HAT VIRTUALIZATION



#### BEGIN NUAGE

[nuage]
vsd1 l1host="FE-SDDC-RH10r" ansible_host=10.116.127.156 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}" srv_dns="['_xmpp-client._tcp.xmpp','1 100 5222']" additional_dns="xmpp"
vsd2 l1host="FE-SDDC-RH11r" ansible_host=10.116.127.157 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}" srv_dns="['_xmpp-client._tcp.xmpp','2 100 5222']" additional_dns="xmpp"
vsd3 l1host="FE-SDDC-RH12r" ansible_host=10.116.127.158 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}" srv_dns="['_xmpp-client._tcp.xmpp','3 100 5222']" additional_dns="xmpp"
c1 l1host="FE-SDDC-RH11r" ansible_host=10.116.127.162 nic_attachments="[ {{ infrastructure_network_services }}, {{ infrastructure_network_tenant }} ]" default_route_via="{{ infrastructure_network_services }}" additional_dns="vsc1"
c2 l1host="FE-SDDC-RH12r" ansible_host=10.116.127.163 nic_attachments="[ {{ infrastructure_network_services }}, {{ infrastructure_network_tenant }} ]" default_route_via="{{ infrastructure_network_services }}" additional_dns="vsc2"
c3 l1host="FE-SDDC-RH11r" ansible_host=10.116.127.164 nic_attachments="[ {{ infrastructure_network_services }}, {{ infrastructure_network_tenant }} ]" default_route_via="{{ infrastructure_network_services }}" additional_dns="vsc3"
c4 l1host="FE-SDDC-RH12r" ansible_host=10.116.127.165 nic_attachments="[ {{ infrastructure_network_services }}, {{ infrastructure_network_tenant }} ]" default_route_via="{{ infrastructure_network_services }}" additional_dns="vsc4"
elastic1 l1host="FE-SDDC-RH10r" ansible_host=10.116.127.159 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}"
elastic2 l1host="FE-SDDC-RH11r" ansible_host=10.116.127.160 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}"
elastic3 l1host="FE-SDDC-RH12r" ansible_host=10.116.127.161 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}"
r1 l1host="FE-SDDC-RH11r" ansible_host=10.116.127.166 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}" additional_dns="vsr1"
r2 l1host="FE-SDDC-RH12r" ansible_host=10.116.127.168 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}" additional_dns="vsr2"

[nuage-vsd]
vsd1
vsd2
vsd3

[nuage-elastic]
elastic1
elastic2
elastic3

#### END NUAGE



#### BEGIN OPENSTACK

[rhosp-director-group]
rhosp-director  l1host="FE-SDDC-RH11r" ansible_host=10.116.127.172 activation_key="AK-CV-RHOSP-{{ stage }}" additional_dns="director" provisioning_admin_vip="192.168.105.74" provisioning_dhcp_start="192.168.105.10" provisioning_dhcp_end="192.168.105.25" provisioning_discovery_start="192.168.105.26" provisioning_discovery_end="192.168.105.41" stack_name="overcloud"
rhosp-director2 l1host="FE-SDDC-RH12r" ansible_host=10.116.127.175 activation_key="AK-CV-RHOSP-{{ stage }}" additional_dns="director2" provisioning_admin_vip="192.168.105.75" provisioning_dhcp_start="192.168.105.42" provisioning_dhcp_end="192.168.105.57" provisioning_discovery_start="192.168.105.58" provisioning_discovery_end="192.168.105.73" stack_name="overcloud2"

# The group of all osp compute nodes
[rhosp-compute]
#rhosp-compute1  ansible_host=10.116.127.143 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.103" boot_mac="1c:98:ec:18:be:fe" root_disk="PDNNF0ARH311IW"
#rhosp-compute2  ansible_host=10.116.127.144 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.104" boot_mac="1c:98:ec:14:59:2a" root_disk="PDNNF0ARH311I3"
#rhosp-compute3  ansible_host=10.116.127.145 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.105" boot_mac="1c:98:ec:18:ae:0a" root_disk="PDNNF0ARH311JM"
#rhosp-compute4  ansible_host=10.116.127.146 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.106" boot_mac="1c:98:ec:18:ae:aa" root_disk="PDNNF0ARH311HY"
#rhosp-compute5  ansible_host=10.116.127.147 activation_key="AK-CV-RHOSP-{{ stage }}"
#rhosp-compute6  ansible_host=10.116.127.148 activation_key="AK-CV-RHOSP-{{ stage }}"
#rhosp-compute7  ansible_host=10.116.127.149 activation_key="AK-CV-RHOSP-{{ stage }}"
#rhosp-compute8  ansible_host=10.116.127.150 activation_key="AK-CV-RHOSP-{{ stage }}"

# The group of all osp control nodes
[rhosp-control]
#rhosp-control1  ansible_host=10.116.127.140 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.100" boot_mac="1c:98:ec:18:9e:ee" root_disk="PDNNF0ARH311IZ"
#rhosp-control2  ansible_host=10.116.127.141 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.101" boot_mac="1c:98:ec:18:be:ea" root_disk="PDNNF0ARH311OW"
#rhosp-control3  ansible_host=10.116.127.142 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.102" boot_mac="1c:98:ec:17:1f:ba" root_disk="PDNNF0ARH311HU"
#rhosp-control4  ansible_host=10.116.127.151 activation_key="AK-CV-RHOSP-{{ stage }}"

# A list of all OpenStack subgroups
[rhosp-all-group:children]
rhosp-director-group
rhosp-undercloud

# The groups that make up the osp undercloud (i.e. compute, control and potentially storage)
[rhosp-undercloud:children]
rhosp-compute
rhosp-control

# a group required to store a common configuration for IPMI emulation between the layer1 host and the osp-director
[layer1-rhosp:children]
rhosp-director-group
layer1-group

# virtual IPs - these will not be instantiated through Ansible (but need them for DNS records, DNAT, etc)
# there should be at least two IPs distance between the VIPs since two VIPs are allocated on the internal_api network
[vips]
openstack         ansible_host=10.116.127.173 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}"
openstack2        ansible_host=10.116.127.176 nic_attachments="[ {{ infrastructure_network_services }} ]" default_route_via="{{ infrastructure_network_services }}"

[overcloud-director-group]
rhosp-director

[overcloud-controller-group]
fe-sddc-rh1r    ansible_host=10.116.127.140 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.100" boot_mac="1c:98:ec:18:9e:ee" root_disk="PDNNF0ARH311IZ"
fe-sddc-rh2r    ansible_host=10.116.127.141 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.101" boot_mac="1c:98:ec:18:be:ea" root_disk="600508b1001c59f0ec98290410df1425"
fe-sddc-rh3r    ansible_host=10.116.127.142 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.102" boot_mac="1c:98:ec:17:1f:ba" root_disk="600508b1001cfe9e58073f58ed12cdfa"


[overcloud-compute-group]
fe-sddc-rh4r    ansible_host=10.116.127.143 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.103" boot_mac="1c:98:ec:18:be:fe" root_disk="600508b1001c17807806d7336bcde0e7"
fe-sddc-rh5r    ansible_host=10.116.127.144 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.104" boot_mac="1c:98:ec:14:59:2a" root_disk="600508b1001c829c25b254486c2bdbc4"
fe-sddc-rh6r    ansible_host=10.116.127.145 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.105" boot_mac="1c:98:ec:18:ae:0a" root_disk="600508b1001c0c585d6f013cda22e00d"
fe-sddc-rh7r    ansible_host=10.116.127.146 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.106" boot_mac="1c:98:ec:18:ae:aa" root_disk="600508b1001cf7a18f48f1d733e3984d"
fe-sddc-rh8r    ansible_host=10.116.127.147 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.107" boot_mac="1c:98:ec:18:ae:8a" root_disk="abc"
fe-sddc-rh9r    ansible_host=10.116.127.148 activation_key="AK-CV-RHOSP-{{ stage }}" pm_addr="10.116.127.108" boot_mac="1c:98:ec:18:ae:1a" root_disk="abc"



[overcloud2-director-group]
rhosp-director2

[overcloud2-compute-group]
#rhosp-compute8

[overcloud2-controller-group]
#rhosp-control4


#### END OPENSTACK



#### BEGIN RH-SSO

[rh-sso-group]
rh-sso activation_key="AK-CV-RH-SSO-{{ stage }}" additional_dns="sso"

[rh-sso-l2-vm-group]
#rh-sso ansible_host=10.116.127.7

[rh-sso-osp-vm-group]
rh-sso osp_tenant="{{ rhsso_tenant }}" osp_flavor="m1.medium" osp_image="RHEL7"

[rh-sso-rhv-vm-group]
#rh-sso ansible_host=10.116.127.7

#### END RH-SSO



#### BEGIN OPENSHIFT

[ocp-master-group]
ocp-master1  Xansible_host=10.116.127.20 jump_host=ocp-bastion openshift_node_labels="{'region': 'master', 'zone': 'default', 'logging-infra-fluentd': 'true', 'openshift_schedulable': 'false'}" activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"
ocp-master2  Xansible_host=10.116.127.21 jump_host=ocp-bastion openshift_node_labels="{'region': 'master', 'zone': 'default', 'logging-infra-fluentd': 'true', 'openshift_schedulable': 'false'}" activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"
ocp-master3  Xansible_host=10.116.127.22 jump_host=ocp-bastion openshift_node_labels="{'region': 'master', 'zone': 'default', 'logging-infra-fluentd': 'true', 'openshift_schedulable': 'false'}" activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"

[ocp-node-group]
ocp-infranode1 Xansible_host=10.116.127.23 jump_host=ocp-bastion openshift_node_labels="{'region': 'infra', 'zone': 'default', 'logging-infra-fluentd': 'true'}" activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"
ocp-infranode2 Xansible_host=10.116.127.24 jump_host=ocp-bastion openshift_node_labels="{'region': 'infra', 'zone': 'default', 'logging-infra-fluentd': 'true'}" activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"
ocp-node1      Xansible_host=10.116.127.25 jump_host=ocp-bastion openshift_node_labels="{'region': 'primary', 'zone': 'east', 'logging-infra-fluentd': 'true'}"  activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"
ocp-node2      Xansible_host=10.116.127.26 jump_host=ocp-bastion openshift_node_labels="{'region': 'primary', 'zone': 'west', 'logging-infra-fluentd': 'true'}"  activation_key="AK-CV-RHOSE3-{{ stage }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.large" osp_image="RHEL7"

# comment out the entry if you do not want a load balancer VM set up
[ocp-l2-or-rhv-lb-group]
#ocp-l2-lb         activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" Xadditional_dns="openshift" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.medium" osp_image="RHEL7"

[ocp-osp-lbaas-group]
ocp-osp-master-lbaas   additional_dns="openshift" osp_tenant="{{ ocp_tenant }}" balances="ocp-master-group" vm_secgroups="['loadbalancer-{{ ocp_tenant }}']"
ocp-osp-infra-lbaas    additional_dns="*.apps" osp_tenant="{{ ocp_tenant }}" balances="ocp-infra-group" vm_secgroups="['loadbalancer-{{ ocp_tenant }}']"

[ocp-osp-bastion-group]
ocp-bastion  activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" pool_regex="{{ rhel_subscription_pool_regex }}" osp_tenant="{{ ocp_tenant }}" osp_flavor="m1.small" osp_image="RHEL7"

[ocp-infra-group]
ocp-infranode1
ocp-infranode2

[ocp-common-group:children]
ocp-master-group
ocp-node-group

# if this group contains any members, OSP setup and integration (i.e. cinder storage) will be configured
[ocp-osp-vm-group:children]
ocp-master-group
ocp-node-group
ocp-osp-bastion-group

[ocp-l2-vm-group:children]
ocp-l2-or-rhv-lb-group
#ocp-master-group
#ocp-node-group

[ocp-rhv-vm-group:children]
#ocp-l2-or-rhv-lb-group
#ocp-master-group
#ocp-node-group

# the node where the ansible playbook will run
[ocp-installer-group]
ocp-master1

#### END OPENSHIFT


#### BEGIN CLOUDFORMS

#[cloudforms]
#cloudforms      ansible_host=10.116.127.17 activation_key="AK-CV-CLOUDFORMS-{{ stage }}"

[cloudforms-db]
cloudforms-db01       jump_host=cloudforms-ui01 Xansible_host=10.116.127.201 activation_key="AK-CV-CLOUDFORMS-{{ stage }}" cf_zone="Database" cf_type="db" cf_roles="database_operations,reporting,scheduler,user_interface,web_services,websocket" osp_tenant="{{ cf_tenant }}" osp_flavor="m1.xlarge" osp_image="Cloudforms"


[cloudforms-ui]
cloudforms-ui01   Xansible_host=10.116.127.202 activation_key="AK-CV-CLOUDFORMS-{{ stage }}" cf_zone="WebUI" cf_type="ui" cf_use_rhsso=true cf_roles="automate,database_operations,notifier,user_interface,web_services,websocket" osp_tenant="{{ cf_tenant }}" osp_flavor="cf.xlarge" osp_image="Cloudforms" additional_dns="cloudforms"

[cloudforms-wk-ocp]
cloudforms-wk-ocp01   jump_host=cloudforms-ui01 Xansible_host=10.116.127.203 activation_key="AK-CV-CLOUDFORMS-{{ stage }}" cf_zone="OCP" cf_type="wk-ocp" cf_roles="automate,database_operations,ems_inventory,ems_metrics_collector,ems_metrics_coordinator,ems_metrics_processor,ems_operations,event,smartproxy,smartstate,user_interface,web_services,websocket" osp_tenant="{{ cf_tenant }}" osp_flavor="cf.xlarge" osp_image="Cloudforms"

[cloudforms-wk-osp]
cloudforms-wk-osp01  jump_host=cloudforms-ui01 Xansible_host=10.116.127.204 activation_key="AK-CV-CLOUDFORMS-{{ stage }}" cf_zone="OSP" cf_type="wk-osp" cf_roles="automate,database_operations,ems_inventory,ems_metrics_collector,ems_metrics_coordinator,ems_metrics_processor,ems_operations,event,smartproxy,smartstate,user_interface,web_services,websocket" osp_tenant="{{ cf_tenant }}" osp_flavor="cf.xlarge" osp_image="Cloudforms"

[cloudforms-wk-rhev]
#cloudforms-wk-rhev01  jump_host=cloudforms-ui01 Xansible_host=10.116.127.205 activation_key="AK-CV-CLOUDFORMS-{{ stage }}" cf_zone="RHV" cf_type="wk-rhev" cf_roles="automate,database_operations,ems_inventory,ems_metrics_collector,ems_metrics_coordinator,ems_metrics_processor,ems_operations,event,smartproxy,smartstate,user_interface,web_services,websocket" osp_tenant="{{ cf_tenant }}" osp_flavor="cf.xlarge" osp_image="Cloudforms"

[cloudforms-group:children]
cloudforms-db
cloudforms-ui
cloudforms-wk-ocp
cloudforms-wk-osp
cloudforms-wk-rhev

[cf-osp-vm-group:children]
cloudforms-group

[cf-rhv-vm-group:children]
#cloudforms-group

#### END CLOUDFORMS


#### BEGIN ANSIBLE TOWER

[tower]
#tower          l1host="FE-SDDC-RH10r" ansible_host=10.116.127.38 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}"

[ansible-jump-host]
ansible-jump-demo-vms  activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" osp_tenant="demo-vms" osp_flavor="m1.small" osp_image="RHEL7"
#ansible-jump-demo-infra  activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" osp_tenant="demo-infra" osp_flavor="m1.small" osp_image="RHEL7"

#### END ANSIBLE TOWER



#### BEGIN DEMO CONTENT

[dev-client-group]
#dev-client     ansible_host=10.116.127.37 activation_key="AK-CV-RHOSE3-CLIENT-{{ stage }}"

[lookbusy-rhev-group]
#lookbusy-rhev   ansible_host=10.116.127.39 activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" rhev_image="RHEL7" nic_attachments="[ {{ infrastructure_network_services }},{{ infrastructure_network_admin }} ]"

# layer 3 openstack
[lookbusy-osp-group]
lookbusy-osp    activation_key="AK-CV-OS-RHEL7-SERVER-{{ stage }}" osp_tenant="demo-infra" osp_flavor="m1.small" osp_image="RHEL7"

[lookbusy-group:children]
lookbusy-osp-group
lookbusy-rhev-group

#### END DEMO CONTENT



#### BEGIN STORAGE (OBSOLETE)

[ceph]
#will be filled in dynamically via layer2_ceph_inventory role
#ceph1 ansible_host=10.116.127.2 activation_key="AK-CV-CEPH-{{ stage }}"
#ceph2 ansible_host=10.116.127.3 activation_key="AK-CV-CEPH-{{ stage }}"
#ceph3 ansible_host=10.116.127.4 activation_key="AK-CV-CEPH-{{ stage }}"
#ceph4 ansible_host=10.116.127.5 activation_key="AK-CV-CEPH-{{ stage }}"

[storage-console]
#storage-console ansible_host=10.116.127.9 activation_key="AK-CV-CEPH-{{ stage }}"

#### END STORAGE (OBSOLETE)


[laptop]
localhost              ansible_connection=local openshift_master_api_host_and_port='openshift.{{ hailstorm_dns_domain }}:443'


#### BEGIN ADDITIONAL GROUPS


# All layer2 node groups that are installed with RHEL7
[rhel7:children]
proxy-group
satellite-group
ipa-group
install-host-group
infrastructure-group
bosch-vpn-group
efk-group
rh-sso-group
rhosp-all-group
rhvh-group
ocp-l2-or-rhv-lb-group
ocp-master-group
ocp-node-group
ocp-osp-bastion-group
cloudforms-group
lookbusy-group
dev-client-group
tower
ansible-jump-host
storage-console

# All layer2 node groups that are installed with RHEL6
[rhel6:children]
#test-rhel6

# everything on layer2
[layer2:children]
proxy-group
satellite-group
ipa-group
install-host-group
infrastructure-group
bosch-vpn-group
nuage
rh-sso-l2-vm-group
ocp-l2-vm-group
rhv-group
rhosp-all-group
efk-group
dev-client-group
tower
storage-console
windows-group

# to let it participate in the calculation of ansible_host
# and the ssh proxy command used to communicate with all layer2/3 hosts
[accessible_via_underlay:children]
layer2
vips
lookbusy-rhev-group
bosch-vpn-group
cf-rhv-vm-group
cf-osp-vm-group
rh-sso-rhv-vm-group
rh-sso-l2-vm-group
ocp-l2-vm-group
ocp-rhv-vm-group
sddc

[accessible_via_floating_ip:children]
ansible-jump-host
lookbusy-osp-group
ocp-osp-vm-group
cf-osp-vm-group
rh-sso-osp-vm-group

[accessible_via_services_network:children]
nuage

# to let it participate in the calculation of vm_nics
[automated_vmnics_calculation:children]
accessible_via_floating_ip
accessible_via_underlay
accessible_via_services_network
overcloud-controller-group
overcloud-compute-group

# A group to capture all nodes with standard 3-NIC network layout (services, admin, storage)
[niclayout-standard:children]
install-host-group
nuage
satellite-group
infrastructure-group
ipa-group
efk-group
rhvm-group
lookbusy-rhev-group
dev-client-group
tower
storage-console
bosch-vpn-group
rh-sso-rhv-vm-group
rh-sso-l2-vm-group
ocp-l2-vm-group
ocp-rhv-vm-group

[haproxy_frontend]
infrastructure

[haproxy_backend]
ocp-master1
ocp-master2
ocp-master3
